{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787106b0",
   "metadata": {},
   "source": [
    "# Tiling Whole Slide Images\n",
    "This section will be the second step of our dataset processing, in this section we will tile our svs files into smaller tiff files so that it would become more managable and readable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a44d1cf",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87581735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openslide_path = r\"C:\\Users\\aaron\\openslide-win64-20171122\\openslide-win64-20171122\\bin\"\n",
    "os.environ['PATH'] = openslide_path + \";\" + os.environ['PATH']\n",
    "from openslide import open_slide\n",
    "import openslide\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from openslide.deepzoom import DeepZoomGenerator #For tiling and zoom\n",
    "from NormHnE import norm_HnE\n",
    "import tifffile as tiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456443cf",
   "metadata": {},
   "source": [
    "#### Intial Testing\n",
    "This step involves doing intial testing this is to check if the WSI will be tiled properly and also is essential for section 3 this slide will be used to create the simple filter of tiles that will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbda8782",
   "metadata": {},
   "outputs": [],
   "source": [
    "slide = open_slide(\"D:/Downloads/Grades Folder/SVS-20221218T164716Z-001/SVS/TCGA-2Z-A9JO-01A-01-TS1.6DC87048-FE1E-4795-959F-5AF85DECB6CE.svs\") #opening slide using openslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa584ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = DeepZoomGenerator(slide, tile_size=1000, overlap=0, limit_bounds=False) # calling deepzoom generator to zoom in to the slide into a 1000x1000 pixel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1712c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles.level_count # counting how many levels are present in the deepzoomed slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c308827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols,rows = tiles.level_tiles[10] # dividing the max tile level into its rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc20d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(rows): # looping over every single row\n",
    "        for col in range(cols): #looping over every single column\n",
    "            tile_name = str(col) + \"_\" + str(row) # creating tile name based on column_row number\n",
    "            #tile_name = os.path.join(tile_dir, '%d_%d' % (col, row))\n",
    "            #print(\"Now processing tile with title: \", tile_name)\n",
    "            temp_tile = tiles.get_tile(10, (col, row)) # getting all the tiles in the highes level tile\n",
    "            temp_tile_RGB = temp_tile.convert('RGB') # converting to rgb since some images may be in rgba\n",
    "            temp_tile_np = np.array(temp_tile_RGB) # converting the image into an array\n",
    "        \n",
    "            if temp_tile_np.mean() < 200 and temp_tile_np.std() > 50: # using the mean and std generated from blank_partial_good to indicate which tiles to save\n",
    "                print(\"Processing tile number:\", tile_name)\n",
    "                norm_img, H_img, E_img = norm_HnE(temp_tile_np, Io=240, alpha=1, beta=0.15) # Calling the norm H&E package\n",
    "                #Save the norm tile, H and E tiles      \n",
    "                tiff.imsave(\"D:/Downloads/Grades Folder/SVS-20221218T164716Z-001/SVS/A9JO/\"+tile_name + \"_norm.tif\", norm_img) # Saving all the H files\n",
    "                tiff.imsave(\"D:/Downloads/Grades Folder/SVS-20221218T164716Z-001/SVS/A9JO/\"+tile_name + \"_H.tif\", H_img) # Saving all the E files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a31bc",
   "metadata": {},
   "source": [
    "#### Actual Tiling of SVS files\n",
    "This step will be similar to the inital testing above except this step has another for loop that will loop over all the SVS files found in level0 folder which contains the SVS files that will be used. Note: The function used to get the normalized and hematoxilyn slide is in a seperate .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d5a21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src_dir = \"E:/level0/\" # Whole Slide Images directory\n",
    "ot_dir = \"D:/level1/\" # Destination of Tiled files\n",
    "for (dirpath, dirnames, filenames) in os.walk(src_dir): # Checking WSI directory for all files\n",
    "    print(filenames)\n",
    "    for fname in filenames: # Getting filenames\n",
    "        norml_img=os.path.join(ot_dir+fname+\"/Norm/\") # Creating filename for generated norm images\n",
    "        Hl_img=os.path.join(ot_dir+fname+\"/H/\") # Creating filename for generated norm images\n",
    "        slide = open_slide(os.path.join(src_dir+fname+\"/\"+fname)) # Opening the slide based on the filename from the WSI folder\n",
    "        tiles = DeepZoomGenerator(slide, tile_size=1000, overlap=0, limit_bounds=False) # calling deepzoom generator to zoom in to the slide into a 1000x1000 pixel size\n",
    "        cols,rows = tiles.level_tiles[12] # Splitting tiles into columns and rows and setting the tile level to 12\n",
    "        \n",
    "        for row in range(rows): # looping over every single row\n",
    "            for col in range(cols): # looping over every single column\n",
    "                tile_name = str(col) + \"_\" + str(row) # Creating filename for generated tile\n",
    "                #tile_name = os.path.join(tile_dir, '%d_%d' % (col, row))\n",
    "                #print(\"Now processing tile with title: \", tile_name)\n",
    "                temp_tile = tiles.get_tile(12, (col, row)) # getting all the tiles in the highest level tile based on columns and rows\n",
    "                temp_tile_RGB = temp_tile.convert('RGB') # converting to rgb since some images may be in rgba\n",
    "                temp_tile_np = np.array(temp_tile_RGB) # converting the image into an array\n",
    "        \n",
    "                if temp_tile_np.mean() < 200 and temp_tile_np.std() > 50:# using the mean and std generated from blank_partial_good to indicate which tiles to save\n",
    "                    print(\"Processing tile number:\", tile_name,fname) \n",
    "                    norm_img, H_img, E_img = norm_HnE(temp_tile_np, Io=240, alpha=1, beta=0.15) # Calling the norm H&E packages      \n",
    "                    tiff.imsave(norml_img+tile_name + \"_norm.tif\", norm_img) # Saving all the norm tiles\n",
    "                    tiff.imsave(Hl_img+tile_name + \"_H.tif\", H_img) # Saving all the H tiles\n",
    "                    \n",
    "# Note: in the case of the paper we used the Hematoxilyn slides instead of the normalized tiles just delete the tiff.imsave for the tile you do not need        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82773a94",
   "metadata": {},
   "source": [
    "### Cellprofiler Preprocessing\n",
    "The cellprofiler will only get the features of 20 images per patient to lessen the computation time and when using the whole dataset it would take a very long time to process the entire thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d802f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shutil, random, os\n",
    "import fnmatch\n",
    "for file in os.listdir('D:/level1/'): # Going over all the files in Tiles directory\n",
    "    dirpath = os.path.join('D:/level1/'+file+'/H') # Creating file names of hematoxilyn images\n",
    "    destDirectory = 'D:/Level2/' # Destination directory\n",
    "    count = len(fnmatch.filter(os.listdir(dirpath), '*.*')) # Counting all the available files per folder\n",
    "    print('File Count:', count)\n",
    "    if count >= 20: # if folder has more than 20 files proceed with the code\n",
    "        filenames = random.sample(os.listdir(dirpath), 20) # Getting 20 random files from a folder    \n",
    "        for fname in filenames: # Looping over the 20 selected files\n",
    "            srcpath = os.path.join(dirpath, fname) # Creating folder path for the 20 files\n",
    "            shutil.copy(srcpath, os.path.join(destDirectory,file)) # Copying the files into the destination folder\n",
    "    else: # else if folder has less than 20 files stop the code\n",
    "        print(\"noway\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f99ce459c7a0f9093dec66807a6e7241d1f758b2e574ff2d27df5e1d05a50f5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
