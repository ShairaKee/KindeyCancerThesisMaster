{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c24598b",
   "metadata": {},
   "source": [
    "# Post Cellprofiler Data Processing\n",
    "This section will process the data coming from cellprofiler to make the data more managable and more readable which will then be passed through a feature elimination on the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44997a53",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d446982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a6f7b",
   "metadata": {},
   "source": [
    "#### Setting max displayed Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed6729",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a7b347",
   "metadata": {},
   "source": [
    "#### Loading in Data\n",
    "This data is the Object features detected from the slides fed to the cell profiler. The output of the cell profiler will be a csv which will contain all the detected objects placed into seperate columns. Object feature detection focuses the detection of the nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/CellProfiler Output/Batch Testing/Batch_TestDilateObjects2.csv')#Data generated from cell profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c390691",
   "metadata": {},
   "source": [
    "#### Data manipulation\n",
    "Getting the average of the detected feature per slide. This means that the output csv file will contain the all the detected features in each slide and place it by row. To process the data it is necessary to get the mean of the rows per slide to get the whole picture of the silde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a589ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Avedata = df.groupby(df[\"ImageNumber\"]).mean()#Getting mean of the rows per slide\n",
    "Avedata #Displaying the rows\n",
    "Avedata.to_csv(\"Batch_ObjectFeatures_Unprocessed.csv\")#Saving the data into a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc32411",
   "metadata": {},
   "source": [
    "#### Resetting the max rows to see the entire dataset\n",
    "This part is necessary to check wether there are missing rows/columns in the averaged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecb405",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 7340) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e704e",
   "metadata": {},
   "source": [
    "#### Additional Data Manipulation\n",
    "After initially processing the data grouping together the rows by thier slides the next step is to group together the slides by their patient. Since in our study there are 20 slides per patient we got every 20 rows from the dataset and got its mean to get the average features per patient. This would make the dataset more managable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c40178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBP = Avedata.groupby(np.arange(len(g))//20).mean()#Getting the mean of every 20 rows from the dataset (GBP-GROUPED BY PATIENTS)\n",
    "GBP.to_csv(\"ObjectFeatures_Generated.csv\")#Saving Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620bb2e3",
   "metadata": {},
   "source": [
    "### Image Features Processing\n",
    "In image features processing the steps will be similar except we will no longer need to get the average objects detected since this dataset focuses on the per image feature results so the only processing step needed is to average the images per patient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994425a",
   "metadata": {},
   "source": [
    "#### Loading in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/CellProfiler Output/Batch TESTING/Batch_TestImage.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb3c1a",
   "metadata": {},
   "source": [
    "#### Data manipulation\n",
    "This step will group together every 20 rows, this is because there are 20 images per row and we need to get the average for every patient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99688a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBPI = df.groupby(np.arange(len(df[\"ImageNumber\"]))//20).mean()#Getting the mean of every 20 rows from the dataset (GBPI-GROUPED BY PATIENTS IMAGES)\n",
    "z.to_csv(\"Batch_ImageFeatures_Generated.csv\")#Saving Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd725e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
